{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantum Mechanics: Finite Difference Diagonalization\n",
    "## Introduction\n",
    "The key challenge in solving many quantum systems is to find the energy eigenstates for a given potential by solving the time-independent Schrodinger equation:\n",
    "$$ H\\psi_n = \\left(\\frac{p^2}{2m}+V\\right)\\psi_n=E_n\\psi$$\n",
    "When we work in real space, this equation becomes:\n",
    "In real space, it acts on the wavefunction as:\n",
    "$$ H\\psi_n(x) = -\\frac{\\hbar^2}{2m} \\frac{d^2}{dx^2}\\psi(x) + V(x)\\psi_n(x)=E_n\\psi_n(x)$$\n",
    "This differential equation can be quite difficult to solve, and analytic solutions are only available for a few well known systems, like the Infinite Square Well and the Quantum Harmonic Oscillator.  Thus, physicists need to use computers and numerical algorithms in order to solve Schrodinger's equation for most physical systems.  In this notebook you'll learn about one particularly useful (and surprsingly simple!) method to find stationary states for arbitrary 1D potentials - Finite Difference Diagonalization.\n",
    "\n",
    "## Finite Differences\n",
    "The time independent Schrodinger equation involves derivatives of the wavefunction, so a first task is to figure out how to calcualte derivatives of functions on a computer.  One way of doing this is via Finite Differences, which is actually just a fancy way of describing how you learned to do derivatives in Introductory Calculus.  Back then, you learned that the derivative can be defined as:\n",
    "$$ \\frac{df}{dx} = \\lim_{\\Delta x \\rightarrow 0}\\frac{f(x+\\Delta x)-f(x)}{\\Delta x}$$\n",
    "On a computer then, we can get an approximation for the derivative by dropping the limit and simply using a small $\\Delta x$.\n",
    "$$ \\frac{df}{dx} \\approx \\frac{f(x+\\Delta x)-f(x)}{\\Delta x}$$\n",
    "This is called the Forward Difference Approximation to the derivative.  We could also use the Backward Difference Approximation:\n",
    "$$ \\frac{df}{dx} \\approx \\frac{f(x)-f(x-\\Delta x)}{\\Delta x}$$\n",
    "But how do we approximation a second derivative, as appears in the Schrodinger Equation?  One method is to use the Forward Difference Approximation to calculate the first derivative, and use the Backward Difference Appoximation to get the second derivative:\n",
    "$$\\frac{d^2f}{dx^2}\\approx \\frac{d}{dx}\\frac{f(x+\\Delta x)-f(x)}{\\Delta x} \\approx \\frac{f(x+\\Delta x)-2f(x)+f(x-\\Delta)}{\\Delta x^2}$$\n",
    "These approximations to the derivatives should be fairly accurate as long as $\\Delta x$ is small.  How small? Usually we want $\\Delta x$ to be small compared to the distance over which the function varies a lot.  So for a very smooth and gently sloping curve you might be able to use a fairly large $\\Delta x$, whereas you might need a much smaller one for functions that fluctuate sharply.\n",
    "\n",
    "## Discretizing the Schrodinger Equation\n",
    "We can't represent a continuous function on a computer, like $f(x)$.  Instead, we can only record the value of the function at a finite number of positions, and an intuitive choice is to save the values of the function on a regular grid of spatial locations, \n",
    "$$f(x)\\rightarrow f(x_i)$$\n",
    "$$x_i = n\\cdot \\Delta x$$\n",
    "If we discretize space for the Schrodinger Equation by only recording the values of the wavefunction on a regular grid in space, we have:\n",
    "$$ H\\psi_n(x_i) = -\\frac{\\hbar^2}{2m} \\frac{d^2}{dx^2}\\psi(x) + V(x)\\psi_n(x)=E_n\\psi_n(x_i)$$\n",
    "Now if we apply our finite difference approximation for the second derivative, we get a finite difference version of the Time Tndependent Schrodinger Tquation (TISE). Setting $\\hbar=m=1$, we have:\n",
    "$$ H\\psi_(x_i) = -\\frac{1}{2}\\frac{\\psi(x_i+\\Delta x)-2\\psi(x_i) + \\psi(x_i-\\Delta x)}{\\Delta x^2} + V(x_i)\\psi_n(x_i) $$\n",
    "Or, since $x_{i+1}=x_i+\\Delta x$, we have:\n",
    "$$ H\\psi(x_i) = -\\frac{1}{2}\\frac{\\psi(x_{i+1})-2\\psi(x_i) + \\psi(x_{i-1})}{\\Delta x^2} + V(x_i)\\psi(x_i) $$\n",
    "\n",
    "## Matrix Diagonalization\n",
    "If we think of the values of our wavefunction as the elements of a vector:\n",
    "$$\\vec{\\psi}=\\begin{bmatrix} \\psi(x_0) \\\\ \\psi(x_1) \\\\ ... \\\\ \\psi(x_{n-1})\\end{bmatrix}$$\n",
    "We can view the finite difference TISE as a matrix equation:\n",
    "$$H\\vec{\\psi}=-\\frac{1}{2}\\frac{1}{\\Delta x^2}\\begin{bmatrix}-2 & 1 & 0 & ...\\\\1 & -2 & 1 & ... \\\\ & & ... & \\\\ ... & 0 & 1 & -2 \\end{bmatrix} \\begin{bmatrix} \\psi(x_0) \\\\ \\psi(x_1) \\\\ ... \\\\ \\psi(x_{n-1})\\end{bmatrix} + \\begin{bmatrix}V(x_0) &  0 & 0 & ...\\\\0 & V(x_1) & 0 & ... \\\\ & & ... & \\\\ ... & 0 & 0 & V(x_{n-1}) \\end{bmatrix} \\begin{bmatrix} \\psi(x_0) \\\\ \\psi(x_1) \\\\ ... \\\\ \\psi(x_{n-1})\\end{bmatrix}$$\n",
    "This is remarkable, because it means that we have replaced the original differential equation with a much simpler matrix equation for the TISE:\n",
    "$$H\\vec{\\psi}_n=E_n \\vec{\\psi}_n $$\n",
    "But this is just a matrix eigenvalue problem! So, if we want to find the stationary states for the Hamiltonian, then we just need to find the eigenenergies and eigenstates (vectors) for the matrix $H$.  This would be hard to do by hand, but as we'll see diagonalizing even very large matrices is trivial on a computer.  The energies and eigenstates we get will depend on our discretization size - we expect to get more accurate answers the smaller we make $\\Delta x$. \n",
    "\n",
    "## System Size\n",
    "One thing you might have noticed is that in order to have a finite grid, we need to do more than just discretize space. We also need to make the space finite in extent - that is, instead of dealing with $x=-\\infty$ to $x=\\infty$, we deal with a discretized space from $x_0$ to $x_{n-1}$. But how big of a space do we need in order to get accurate answers?\n",
    "\n",
    "The quick answer is that the discretized grid needs to include all positions where the wavefunction has a significant amplitude.  This means that the algorithm will be limited to bound state problems - if the particle is not bound, then the wavefunction oscillates to infinity, and so cutting space off at any distance will produce significant errors. \n",
    "\n",
    "It also means that the size of the space needed will depend one which eigenstates we want to obtain accurately.  Larger energy states tend to take up more space and oscillate more quickly, so we'll need larger grids with finer discretization to compute them accurately.  This is also apparent from the matrix equation we derived - if the space discretization is such that our wavefunction vector has $N$ elements, then the diagonalization of the matrix equation will yield $N$ eigenvectors.  For many bound state problems, such as the Quantum Harmonic Oscillator, the actual number of eigenstates is infinite, so we expect our algorithm to cut off the higher energy states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
